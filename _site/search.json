[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site has been developed as part of the coursework requirements for GSM6027/DATA599-03, Communicating with Data at Willamette University.\nAll projects displayed herein were completed as part of the graduation requirements for the Masters in Data Science program."
  },
  {
    "objectID": "about.html#work-history",
    "href": "about.html#work-history",
    "title": "About",
    "section": "Work History",
    "text": "Work History\n\nThe beginning\nAfter receiving my degree in manufacturing engineering technology I began work at a small, privately owned company that manufactured,, assembled and tested hydraulic valves and manifolds. My primary focusing was on Lean Manufacturing and manual assembly processes. It was here that I became familiar with ISO-9001 and its counterparts. I was privileged enough to be invited to participate in the development of our company’s Lean Academy, working to develop and deliver training courses on several lean manufacturing concepts. These tools and philosophies included 5S, Visual Workshop, Process Standardization, Value Stream Mapping, Total Preventative Maintenance, and Setup Time Reduction, among others.\n\n\nMore lean manufacturing focus\nFor my next role I was recruited to different company that manufactured electrical connectors (large quantity runs with minimal components and high quality requirements). Here I lead efforts in lean manufacturing implementation as well as process flow, specifically in regards to assembly, metal parts stamping, and chemical etching processes. I managed the kaizen tien (improvement suggestion) program which included working with stake holders across all departments. This also required working with management to justify and lead the implementation of the improvement opportunities.\n\n\nFrom ‘widget’ manufacturing to capitol goods\nAfter leaving the previous company, I was hired to work as the primary manufacturing engineer for the assembly, test, and final assembly areas of a large pump manufacturer which made products for the oil and gas industry as well as the power generation (including nuclear) and water markets."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jesse A. DeBolt",
    "section": "",
    "text": "Hello!\nWelcome to my portfolio blog. You can see some of my recent projects and work examples on the ‘Projects’ page. If you are looking to hire someone with extensive manufacturing experience and data familiarity, please take a look at my resume by clicking the Resume button up top. This site is very much in progress so check back for updates and new project examples."
  },
  {
    "objectID": "posts/1-31-23_TidyTuesday/index.html",
    "href": "posts/1-31-23_TidyTuesday/index.html",
    "title": "Tidy Tuesday Recreation",
    "section": "",
    "text": "TidyTuesday\nJoin the R4DS Online Learning Community in the weekly #TidyTuesday event! Every week we post a raw dataset, a chart or article related to that dataset, and ask you to explore the data. While the dataset will be “tamed”, it will not always be tidy! As such you might need to apply various R for Data Science techniques to wrangle the data into a true tidy format. The goal of TidyTuesday is to apply your R skills, get feedback, explore other’s work, and connect with the greater #RStats community! As such we encourage everyone of all skills to participate!\nLoad the weekly Data\nDownload the weekly data and make available in the tt object.\n\nCodett <- tt_load(\"2023-01-24\")\n\n--- Compiling #TidyTuesday Information for 2023-01-24 ----\n\n\n--- There are 4 files available ---\n\n\n--- Starting Download ---\n\n\n\n    Downloading file 1 of 4: `survivalists.csv`\n    Downloading file 2 of 4: `loadouts.csv`\n    Downloading file 3 of 4: `episodes.csv`\n    Downloading file 4 of 4: `seasons.csv`\n\n\n--- Download complete ---\n\n\nReadme\nTake a look at the readme for the weekly data to get insight on the dataset. This includes a data dictionary, source, and a link to an article on the data.\n\nCodett\n\n\nGlimpse Data\nTake an initial look at the format of the data available.\n\nCodett %>% \n  map(glimpse)\n\n\nWrangle\nExplore the data and process it into a nice format for plotting! Access each dataset by name by using a dollarsign after the tt object and then the name of the data set.\n\nCodesurvivalists <- tt$survivalists\nloadouts <- tt$loadouts\nepisodes <- tt$episodes\nseasons <- tt$seasons\n\n\nVisualize\nUsing your processed dataset, create your unique visualization.\n\nCode# Create color palette\noptions(ggplot2.discrete.colour= c(\"#FFFF00\", \"#FF3131\"))\n\nage <- survivalists %>% \n        ggplot(aes(days_lasted, age, color = gender))+\n          geom_point(aes(x = days_lasted, y = age),\n                     shape = 8, size = 1.8, \n                     alpha = 2.0) +\n          theme_classic()+\n            theme(axis.line = element_blank(),\n                  axis.ticks = element_blank(),\n                  legend.position = \"right\",\n                  axis.title.x = element_text(color = \"white\", \n                                              vjust=14, hjust = 0.625),\n                  axis.title.y = element_text(color = \"white\"),\n                  axis.text.x = element_text(vjust = 18, color = \"white\"),\n                  axis.text.y = element_text(hjust = 15, color = \"white\"),\n                  title = element_text(color = \"white\"),\n                  legend.title = element_text(color = \"white\", size = 10),\n                  legend.text = element_text(color = \"white\"),\n                  plot.title = element_text(hjust = 0.6))+\n              labs(x = \"Survivalists' Age\", y = \"Days Lasted\", \n                   title = \"Alone: days lasted versus age\")+\n              scale_y_continuous(limits = c(15, 50))+\n              scale_x_continuous(limits = c(0, 68))+\n              scale_color_discrete(name = \"Gender\")\n              \n# Adding background\nggbackground(age,\"night_background2.png\")\n\n\n\n\nSave Image\nSave your image for sharing. Be sure to use the #TidyTuesday hashtag in your post on twitter!\n\n\nSaving 7 x 5 in image"
  },
  {
    "objectID": "posts/2-13-23_TableExamples/index.html",
    "href": "posts/2-13-23_TableExamples/index.html",
    "title": "Table Examples",
    "section": "",
    "text": "Table example using DT datatables package in R\n\n\n\n\n\nTable example using flextable in R"
  },
  {
    "objectID": "posts/DATA501_Final_Project/index.html",
    "href": "posts/DATA501_Final_Project/index.html",
    "title": "Data Science Fundementals (DATA-501)",
    "section": "",
    "text": "The data set we were working with was the “US Healthcare Spending Per Capita” (source: Dept of Health and Human Services). After completing the initial review and exploratory analysis using a few “top level” R commands and some basic plots we began further analysis. This analysis focused on the questions of how health care costs changed over the time span of 2005 to 2014, as well as what some of the trends were related to the data provided. After looking into these questions, we spent some time with the most recent year available within the data set looking into similar concerns, but at a more regional and local level. With this review and analysis, we were able to discern that health care costs at the personal level had risen over the indicated time spans and that some areas within the United states have drastically different health care costs."
  },
  {
    "objectID": "posts/DATA501_Final_Project/index.html#setting-up-data-aka-data-wrangling",
    "href": "posts/DATA501_Final_Project/index.html#setting-up-data-aka-data-wrangling",
    "title": "Data Science Fundementals (DATA-501)",
    "section": "Setting up data (aka Data Wrangling)",
    "text": "Setting up data (aka Data Wrangling)\nReading in the dataset and performing initial review of the contents within.\n\nCodelibrary(tidyverse)\nlibrary(skimr)\n\nHealthCareSpending <- read.csv(\"..\\\\..\\\\data\\\\healthcareSpending.csv\")\n\nhead(HealthCareSpending)\ntail(HealthCareSpending)\nstr(HealthCareSpending)\nskim(HealthCareSpending)\n\nsummary(HealthCareSpending)\n\nsummary(HealthCareSpending$Y2014)\n\nunique(HealthCareSpending$Code)\nunique(HealthCareSpending$Item)\nunique(HealthCareSpending$Group)\nunique(HealthCareSpending$Region_Number)\nunique(HealthCareSpending$Region_Name)\nunique(HealthCareSpending$State_Name)\nunique(HealthCareSpending$Average_Annual_Percent_Growth)\n\n\n\n \n\nNotes from review of data for consideration moving forward:\nRegions and US as a whole are represented. This causes State_Name appears to have blank values, consider this during further analysis. The variable ‘Item’ appears to all be in (Millions of Dollars). Remove this portion of text, or split to column with units. ‘Code’ and ‘Region_Number’ are redundant to the descriptive names and will likely not be used for any of the analysis. ’Average_Annual_Percent_growth’ should be renamed to shorter, easier name."
  },
  {
    "objectID": "posts/DATA501_Final_Project/index.html#creating-a-more-tidy-dataset-by-addressing-the-notes-made-during-the-initial-review.",
    "href": "posts/DATA501_Final_Project/index.html#creating-a-more-tidy-dataset-by-addressing-the-notes-made-during-the-initial-review.",
    "title": "Data Science Fundementals (DATA-501)",
    "section": "Creating a more “tidy” dataset by addressing the notes made during the initial review.",
    "text": "Creating a more “tidy” dataset by addressing the notes made during the initial review.\nRemoving the (Millions of Dollars) notation after the variable names in the ‘Item’ column and renaming the column name to denote the unit of measure as well as relabeling the Item variable names to a more compressed form. Also, removing ‘Code’ and ‘Region_Number’ as these are redundant to the descriptive names and should not be needed for any of the analysis.\n\nCodehcs <- HealthCareSpending %>%\n  mutate(across('Item', str_replace, '\\\\ \\\\(Millions of Dollars\\\\)', '')) %>%\nselect(-c(1,4))\n\nhcs <- hcs %>%\n  mutate(across('Item', str_replace, 'Personal Health Care', 'Total'))\n\n\n\n \n\nCreating subsets for each assigned problem.\n\nCodehcs2014 <- select(hcs, -c(5:38))\n\nhcs2005 <- select(hcs, -c(5:29))"
  },
  {
    "objectID": "posts/DATA501_Final_Project/index.html#exploring-the-data-using-plots-for-visualization.",
    "href": "posts/DATA501_Final_Project/index.html#exploring-the-data-using-plots-for-visualization.",
    "title": "Data Science Fundementals (DATA-501)",
    "section": "Exploring the data using plots for visualization.",
    "text": "Exploring the data using plots for visualization.\n\n \n\nLooking at the 2005 to 2014 subset:\n\n \n\nScatter plots\n\nCodeggplot(hcs2005) +\n  aes(x = Y2005, y = Y2014) +\n  geom_point() +\n  scale_x_continuous(trans = \"log\")\n  \nggplot(hcs2005) +\n  aes(x = log(Y2005), y = log(Y2014)) +\n  geom_point() +\n  scale_x_continuous(trans = \"log\")\n\nhcs2005 %>% \n  filter(Item == \"Total\") %>% \n    ggplot(aes(Item, Y2005))+\n      geom_point()\n\n\n\n \n\nBox plots\n\nCodeggplot(hcs2005) +\n  aes(x = Region_Name, y = Y2005) +\n  geom_boxplot() +\n  scale_y_continuous(trans = \"log\") +\n  coord_flip() +\n  facet_wrap(vars(Item))\n\nggplot(hcs2005) +\n  aes(x = Item, y = Y2005) +\n  geom_boxplot() +\n  scale_y_continuous(trans = \"log\") +\n  coord_flip() +\n  facet_wrap(vars(Region_Name))\n\n\n\n \n\nBar plots\n\nCodehcs2005_long_us <- hcs2005 %>% \n  pivot_longer(cols = starts_with(\"y\"), names_to = \"year\",\n              names_prefix = \"y\", values_to = \"cost_in_millions\",\n              values_drop_na = TRUE) %>% \n  filter(Group == 'United States')\n\nggplot(hcs2005_long_us) +\n  aes(x = Item, y = cost_in_millions) +\n  geom_col() +\n  coord_flip()\n\nggplot(hcs2005_long_us) +\n  aes(x = Item, y = cost_in_millions, fill = year) +\n  geom_col() +\n  coord_flip()\n\nggplot(hcs2005_long_us) +\n  aes(x = year, weight = cost_in_millions) +\n  geom_bar()\n\n  \nggplot(hcs2005_long_us) +\n  aes(x = cost_in_millions, fill=Item) +\n  geom_histogram(bins = 30) +\n  scale_x_continuous(trans = \"log\")"
  },
  {
    "objectID": "posts/DATA501_Final_Project/index.html#looking-at-the-2014-subset",
    "href": "posts/DATA501_Final_Project/index.html#looking-at-the-2014-subset",
    "title": "Data Science Fundementals (DATA-501)",
    "section": "Looking at the 2014 subset:",
    "text": "Looking at the 2014 subset:\nScatter plots\n\nCodeggplot(hcs2014) +\n  aes(y = Average_Annual_Percent_Growth, x = Y2014) +\n  geom_point(shape = \"circle\", size = 1.5, colour = \"#112446\") +\n  scale_x_continuous(trans = \"log\") +\n  theme_minimal()\n\n\n\n \n\nBox plots\n\nCodehcs2014 %>% \n  ggplot()+\n    geom_boxplot(aes(log(Y2014), Region_Name))+\n    facet_grid(rows = \"State_Name\", facets=4)\n\nggplot(hcs2014) +\n  aes(x = Y2014, y = Item) +\n  geom_boxplot() +\n  scale_x_continuous(trans = \"log\")\n\nggplot(hcs2014) +\n  aes(x = Y2014, y = Region_Name) +\n  geom_boxplot() +\n  scale_x_continuous(trans = \"log\")\n\n\n\n \n\nBar plots\n\nCodeggplot(hcs2014) +\n  aes(x = Item, y = Y2014) +\n  geom_col() +\n  coord_flip()\n\nggplot(hcs2014) +\n  aes(x = Item, y = Y2014, fill = Group) +\n  geom_col() +\n  scale_fill_hue(direction = 1) +\n  coord_flip()\n\nggplot(hcs2014) +\n  aes(x = State_Name, weight = Y2014) +\n  geom_bar() +\n  coord_flip()\n\nggplot(hcs2014) +\n  aes(x = Y2014) +\n  geom_histogram(bins = 30) +\n  scale_x_continuous(trans = \"log\")"
  },
  {
    "objectID": "posts/DATA501_Final_Project/index.html#a.-since-2005-have-healthcare-costs-increaseddecreasedstayed-the-same-or-something-else",
    "href": "posts/DATA501_Final_Project/index.html#a.-since-2005-have-healthcare-costs-increaseddecreasedstayed-the-same-or-something-else",
    "title": "Data Science Fundementals (DATA-501)",
    "section": "1a. Since 2005 have healthcare costs increased/decreased/stayed the same (or something else)?",
    "text": "1a. Since 2005 have healthcare costs increased/decreased/stayed the same (or something else)?\n\nWith this question in mind and the review of the exploratory analysis performed above we should make the assumption that healthcare costs increased between 2005 and 2014.\n\nWe should be able to test this assumption by looking at the ‘Personal Health Care’ data over time since it is a summation of all other ‘Items’. To do this this we will need to pivot the data to allow for listing of all costs for all years categorized to a single column.\n\nCodehcs2005_long <- hcs2005 %>% \n  pivot_longer(cols = starts_with(\"y\"), names_to = \"year\",\n              names_prefix = \"y\", values_to = \"cost_in_millions\",\n              values_drop_na = TRUE)\n\n\n\n \n\nWe will further need to convert the newly created ‘year’ column to date format.\n\nCodehcs2005_long$year <- substring(hcs2005_long$year, 2)\n\nhcs2005_long$year <- ISOdate(hcs2005_long$year, 1, 1) \n\n\n\n \n\nNow that our data is cleaned up we can create the scatter plot and add the linear regression line for analysis.\n\nCodehcs2005_long %>% filter(Item == \"Total\", Region_Name == \"United States\") %>% \n  ggplot(aes(x=year, y=cost_in_millions))+\n  geom_point()+\n  geom_smooth(method=\"lm\", se=FALSE)+\n  labs(x=\"Year\", y=\"Total Health Care Cost\", title=\"Total 2005-2014 US health care costs\")+\n  theme_minimal()\n\n\n\n\n\n \n\nLooking at the line in our plot above we can easily see that the healthcare costs in the United States as a whole have increased between 2005 and 2014. Not only have they increased, but as shown, the costs have risen at a drastic rate.\n\n \n\n\nWith consideration of the information gained from the plot(s) above we can state that our Null Hypothesis is that as time increases personal healthcare costs remain the same. This in turn leads us to our state that our Alternate Hypothesis is that personal health care increases as time progresses.\n\n\n \n\nFor curiosity sake, let’s add in the models for each individual ‘Item’ group.\n\nCodehcs2005_long %>% filter(Region_Name == \"United States\" & \n                          Item != \"Total\") %>% \n  ggplot(aes(x=year, y=log(cost_in_millions), color=Item))+\n    geom_point()+\n    geom_smooth(method=\"lm\", se=FALSE)+\n      theme_minimal()+\n      theme(legend.position=\"bottom\")+\n      scale_color_discrete(guide=guide_legend(nrow=3), name=\"Type\")+\n      labs(x=\"Year\", y=\"Total Health Care Cost (log)\", \n           title=\"Total 2005-2014 US health care costs per type of expense\")\n\n\n\n\n\n \n\nLooking at the plot above we can easily see that the healthcare costs in all categories for the United States as a whole have increased between 2005 and 2014. But we should test this further to be sure.\n\n \n\nLet’s look at fitting the linear regression model.\n\nCodehcs2005us <- hcs2005_long %>% filter(Item == \"Total\", \n                                     Region_Name == \"United States\")\n\nmod2005 <- lm(hcs2005us$cost_in_millions~hcs2005us$year)\n\nsummary(mod2005)\n\n\nCall:\nlm(formula = hcs2005us$cost_in_millions ~ hcs2005us$year)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-27010  -7094   1879  11964  22934 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    -1.530e+06  7.573e+04  -20.20 3.77e-08 ***\nhcs2005us$year  2.942e-03  6.059e-05   48.55 3.58e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 17370 on 8 degrees of freedom\nMultiple R-squared:  0.9966,    Adjusted R-squared:  0.9962 \nF-statistic:  2357 on 1 and 8 DF,  p-value: 3.584e-11\n\n\nFrom the data above provided by our summary we can see, under “Coefficients”, the column labeled “Estimate” gives us a Y-intercept of -1.530e+06 and the coefficient for the independent variable year. With this information we can generate our equation for the regression line:\nCost = 0.002942*(year)\nThe p-value is shown as 3.584e-11 which indicates that the association is statistically significant as it is much less than 0.05 indicating that our Null Hypothesis should be rejected.\n\nWith consideration of our initial question: Since 2005 have healthcare costs increased/decreased/stayed the same (or something else), we can conclude that:\n\n\nThe assumption that healthcare costs increased between 2005 and 2014 is true. This is backed up by our t-test hypothesis testing where we stated that our Null Hypothesis was that as time increases personal healthcare costs remain the same. We also stated that our Alternate Hypothesis was that as time increases so does personal healthcare costs.\n\n\nSimply put, we have confidence that, since 2005, healthcare costs have increased."
  },
  {
    "objectID": "posts/DATA501_Final_Project/index.html#b.-since-2005-what-categories-have-dominated-healthcare-spending",
    "href": "posts/DATA501_Final_Project/index.html#b.-since-2005-what-categories-have-dominated-healthcare-spending",
    "title": "Data Science Fundementals (DATA-501)",
    "section": "1b. Since 2005, what categories have dominated healthcare spending?",
    "text": "1b. Since 2005, what categories have dominated healthcare spending?\n\n \n\nA bar chart would best represent this makeup of the data in regard to the question. Let’s start with a basic bar charts and look, once again, at the United States as a whole.\n\nCodehcs2005_long %>% \n  filter(Group == \"United States\" & Item != \"Total\") %>% \n    ggplot(aes(x = Item, y = log(cost_in_millions))) +\n      geom_col(fill=\"orange\") +\n      coord_flip()+\n      theme_minimal()+\n      labs(x=\"Tyoe of expense\", y=\"Total Health Care Cost (log)\", \n          title=\"Total US health care costs per type of expense\")\n\n\n\n\n\nThe basic bar chart shown above gives a good picture of the various costs but let’s look at how this fared each year. We can do this with another bar chart, but with the additional factor of year.\n\nCodehcs2005_long %>% \n  filter(Group == \"United States\" & Item != \"Total\") %>% \n    ggplot(aes(x = year, y = cost_in_millions, fill = Item)) +\n      geom_col(position = \"dodge\")+\n        theme_minimal()+\n        theme(legend.position=\"bottom\")+\n        scale_fill_discrete(guide=guide_legend(nrow=3), name=\"Type\")+\n        labs(x=\"Year\", y=\"Total Health Care Cost\", \n             title=\"Total 2005-2014 health care costs per type of expense\")\n\n\n\n\n\n \n\n\nRemembering that our question for this problem was what categories have dominated healthcare spending, we can see from the simple bar graph above that hospital care dominated the healthcare spending by a large factor. Beyond hospital care, physician and clinical serveries and prescription drugs were the other leading expenditures. The second graph shows us that this trend continued virtually every year between 2005 and 2014 with only a few exceptions. The top two expenses, hospital and physician care, made up more than 50% of all health care costs every year."
  },
  {
    "objectID": "posts/DATA501_Final_Project/index.html#c.-since-2005-is-there-a-regional-trend-with-respect-to-healthcare-spending",
    "href": "posts/DATA501_Final_Project/index.html#c.-since-2005-is-there-a-regional-trend-with-respect-to-healthcare-spending",
    "title": "Data Science Fundementals (DATA-501)",
    "section": "1c. Since 2005, is there a regional trend with respect to healthcare spending?",
    "text": "1c. Since 2005, is there a regional trend with respect to healthcare spending?\n\n \n\nIn order to determine the trend within each region and compare all regions to each other we will need to make an individual plot for each one. We can accomplish this in a nice fashion by utilizing a facet wrap layout.\n\nCodehcs2005_long %>% filter(Region_Name != \"United States\") %>% \nggplot(aes(x = year, y = cost_in_millions, fill=Region_Name)) +\n  geom_col() +\n  facet_wrap(vars(Region_Name))+\n  theme_minimal()+\n  theme(axis.text.x = element_text(angle = 90))+\n    labs(x=\"Year\", y=\"Total Health Care Cost\", \n         title=\"Comparison of 2005-2014 total regional health care costs\")\n\n\n\n\n\nIn comparison to one another we see some interesting facts. As shown by the heights of each bar within each plot the Southwest part of the United States typically have the highest healthcare costs. The second most expensive region for healthcare costs is the Mideast region with the Far West and Great Lakes regions following close behind having similar expenses between them. New England and the Plains are also close to each other rounding out the regions just above the Rocky Mountains which has the lowest healthcare costs in the nation. From the individual plots we can easily see the trends for each region. Looking at the individual regions we see the trend for each of them is an increase in costs year by year.\n\n\nWe can verify this conclusion by looking at the average personal healthcare costs as a whole across each region. Let’s use a box plot for an alternate view.\n\nCodehcs2005_long %>% filter(Group == \"Region\" & (Item == \"Total\" &\n                        Region_Name != \"United States\")) %>% \n  group_by(year) %>% \n    summarise(avgCost=mean(cost_in_millions), sdCost=sd(cost_in_millions), n=n())\n\n\n\nCodehcs2005_long %>% filter(Group == \"Region\" & (Item == \"Total\" & Region_Name != \"United States\")) %>% \n  ggplot(aes(x=reorder(Region_Name, -cost_in_millions), y=cost_in_millions, group=Region_Name, color=Region_Name))+\n  geom_boxplot()+\n    theme_minimal()+\n    scale_y_continuous(trans = \"log\")+\n    coord_flip()+\n    labs(x=\"Region\", y=\"Total Health Care Cost\", \n         title=\"Comparison of total regional health care costs\", color=\"Region\")\n\n\n\n\n\n \n\nIndeed, this confirms our interpretation of the differences in costs by region trend."
  },
  {
    "objectID": "posts/DATA501_Final_Project/index.html#a.-in-the-most-recent-year-2014-what-were-the-regional-trends-with-respect-to-healthcare-spending",
    "href": "posts/DATA501_Final_Project/index.html#a.-in-the-most-recent-year-2014-what-were-the-regional-trends-with-respect-to-healthcare-spending",
    "title": "Data Science Fundementals (DATA-501)",
    "section": "2a. In the most recent year (2014) what were the regional trends with respect to healthcare spending?",
    "text": "2a. In the most recent year (2014) what were the regional trends with respect to healthcare spending?\nWith this question in mind, the review of the exploratory analysis performed at the beginning, and the results from our analysis of the 2005 to 2014 data we should make the assumption that healthcare costs were dominated by hospital and physician/clinical expenses.\n\n \n\nWe will start by looking at our 2014 data set and making it a bit more tidy for further analysis. We will need to do this by renaming the column that includes our costs and the average growth column.\n\nCodehcs2014_2a <- hcs2014 %>% \n  rename(\"avg_perc_growth\" = \"Average_Annual_Percent_Growth\", \"cost_in_millions\" = \"Y2014\")\n\n\n\n \n\nNow that we have a more manageable data set, we can make some plots to visualize the data a little better.\n\nCodehcs2014_2a %>% filter(Region_Name != \"United States\" & \n                        Item != \"Total\") %>% \nggplot(aes(x = reorder(Item, cost_in_millions), y = log(cost_in_millions))) +\n  geom_col(aes(fill=Item)) +\n    facet_wrap(vars(Region_Name))+\n    theme_minimal()+\n    theme(legend.position = \"none\")+\n    coord_flip()+\n    labs(x=\"Type\", y=\"Total Health Care Cost\", \n         title=\"Comparison of 2014 regional health care costs by type\")\n\n\n\n\n\n \n\nAs we can see, hospital and physician/clinical expenses did, in fact, dominate the personal health care costs in 2014.\nLet’s take another look at the regional trends.\n\nCodehcs2014_2a %>% filter(Group == \"Region\" & Region_Name != \"United States\"\n                      & Item == \"Total\") %>%\n  ggplot(aes(x=reorder(Region_Name, -cost_in_millions), y=cost_in_millions))+\n    geom_col(fill=\"green3\")+\n    coord_flip()+\n    theme_minimal()+\n      labs(x=\"Region\", y=\"Total Health Care Cost\", \n         title=\"2014 Regional health care costs\")\n\n\n\n\n\n \n\n\nAs in our review of the 2005 to 2014 time span, we see that the trend is the Southeast region has the highest personal health care costs and the Rocky Mountain region has the lowest."
  },
  {
    "objectID": "posts/DATA501_Final_Project/index.html#b.-in-the-most-recent-year-2014-how-did-the-far-west-region-compare-to-the-rest-of-the-country",
    "href": "posts/DATA501_Final_Project/index.html#b.-in-the-most-recent-year-2014-how-did-the-far-west-region-compare-to-the-rest-of-the-country",
    "title": "Data Science Fundementals (DATA-501)",
    "section": "2b. In the most recent year (2014) how did the Far West region compare to the rest of the country?",
    "text": "2b. In the most recent year (2014) how did the Far West region compare to the rest of the country?\n\n \n\nIn order to determine how one region compared to another we need to display them together showing the total personal health care costs.\n\nCodehcs2014_regions <- hcs2014_2a %>% \n  filter(Group != \"State\" & Item == \"Total\" & \n          Group != \"United States\") \n\nggplot(hcs2014_regions)+\n  geom_bar(aes(x=reorder(Region_Name, cost_in_millions), y=cost_in_millions,\n               fill=factor(ifelse(Region_Name == \n                  \"Far West\",\"Highlighted\",\"Normal\"))), stat = \"identity\", \n                  position = \"dodge\", show.legend = FALSE)+\n  scale_fill_manual(name=\"Region_Name\", values = c(\"red\", \"grey50\"))+\n  theme_minimal()+\n  coord_flip()+\n  geom_hline(yintercept = mean(hcs2014_regions$cost_in_millions), color=\"blue\")+\n    labs(x=\"Region\", y=\"Total Health Care Cost\", \n         title=\"2014 Regional health care costs\")\n\n\n\n\n\n \n\n\nWe can see that in 2014 the Far West region did not fare too well in comparison to the other regions. The Far West region is the third highest in overall personal health care costs. With the use of the line in the graph which indicates the average personal health care costs for all regions we also see that the Far West is relatively higher than average."
  },
  {
    "objectID": "posts/DATA501_Final_Project/index.html#c.-in-the-most-recent-year-2014-how-did-oregon-compare-to-the-rest-of-the-far-west-region",
    "href": "posts/DATA501_Final_Project/index.html#c.-in-the-most-recent-year-2014-how-did-oregon-compare-to-the-rest-of-the-far-west-region",
    "title": "Data Science Fundementals (DATA-501)",
    "section": "2c. In the most recent year (2014) how did Oregon compare to the rest of the Far West region?",
    "text": "2c. In the most recent year (2014) how did Oregon compare to the rest of the Far West region?\nThis question is similar to 2b and can be addressed in a similar manner after some filtering of the data.\n\nCodehcs2014_or <- hcs2014_2a %>% \n  filter(Group == \"State\" & Item == \"Total\" & Region_Name == \"Far West\") \n\nggplot(hcs2014_or)+\n  geom_bar(aes(x=reorder(State_Name, cost_in_millions), y=cost_in_millions, \n            fill=factor(ifelse(State_Name == \"Oregon\",\"Highlighted\",\"Normal\"))), \n            stat = \"identity\", position = \"dodge\", show.legend = FALSE)+\n  scale_fill_manual(name=\"Region_Name\", values = c(\"red\", \"grey50\"))+\n  coord_flip()+\n  theme_minimal()+\n  geom_hline(yintercept = mean(hcs2014_or$cost_in_millions), color=\"blue\")+\n    labs(x=\"State\", y=\"Total Health Care Cost\", \n         title=\"2014 Health care costs at state level\")\n\n\n\n\n\n \n\n\nHere we can see that in 2014 Oregon is about in the middle in comparison to the other states within the Far West region. With the use of the line in the graph which indicates the average personal health care costs for all states in the region, we see that Oregon is below the average, however it could be argued that California is causing some skewness to the data."
  },
  {
    "objectID": "posts/DATA502_Viz_Final_Project/index.html",
    "href": "posts/DATA502_Viz_Final_Project/index.html",
    "title": "Data Visualization(DATA-502)",
    "section": "",
    "text": "Prep\n\nCodelibrary(tidyverse)\nlibrary(plotly)\nlibrary(gapminder)\nlibrary(ggrepel)\nlibrary(RColorBrewer)\n\n\nReading in original data\n\nCodeFood_Supply_kcal <- read.csv(\"..\\\\..\\\\data\\\\Food_Supply_kcal_Data.csv\", header = TRUE)\n\nkcal_continents_trimmed <- read.csv(\"..\\\\..\\\\data\\\\kcal_continent_trimmed.csv\", header = TRUE)\n\n\nCreating outlier groups\n\nCodeusa <- kcal_continents_trimmed %>% \n  filter(Country == 'United States')\nslovakia <- kcal_continents_trimmed %>% \n  filter(Country == 'Slovakia')\nnigeria <- kcal_continents_trimmed %>% \n  filter(Country == 'Nigeria')\n\n\nCreating country groups\n\nCodeEurope <- kcal_continents_trimmed %>% \n  filter(Continent == 'Europe')\nNorthAmerica <- kcal_continents_trimmed %>% \n  filter(Continent == 'North America')\nSouthAmerica <- kcal_continents_trimmed %>% \n  filter(Continent == 'South America')\nAfrica <- kcal_continents_trimmed %>% \n  filter(Continent == 'Africa')\n\nAmericas <- kcal_continents_trimmed %>% \n  filter(Continent == 'North America' | Continent == 'South America')\n\n\nAll with no labels\n\nCodeggplot(kcal_continents_trimmed, aes(x=Vegetal.Products, y=Animal.fats,\n        size=Deaths, color=Continent, text=paste(Country)))+\n  scale_color_brewer(palette=\"Dark2\")+\n  geom_point(alpha=0.35, aes(size=(Deaths*1000)))+\n    scale_size_continuous(name = \"Deaths per 1000\")+\n    scale_x_continuous(limits = c(27, 48.5))+\n\n  #US and high/low outliers\n  # geom_point(data = usa, aes(x=Vegetal.Products, y=Animal.fats), \n  #            color = \"#E7298A\", size=5)+\n  #   geom_label_repel(data = usa, aes(x=Vegetal.Products, y=Animal.fats, \n  #                   label = Country), fontface=\"bold\", size=4,\n  #                   nudge_x = -4.75, nudge_y = -1.0)+\n  # geom_point(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats),\n  #            color = \"#7570B3\", size=4)+\n  #   geom_label_repel(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats,\n  #                   label = Country), fontface=\"bold\", size=4,\n  #                   nudge_x = 2.75, nudge_y = -0.5)+\n  # geom_point(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats),\n  #            color = \"#1B9E77\")+\n  #   geom_label_repel(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats,\n  #                   label = Country), fontface=\"bold\", size=4, \n  #                   nudge_x = -1.5, nudge_y = 1.7)+\n  \n  #Quadrant lines\n  geom_vline(xintercept = mean(kcal_continents_trimmed$Vegetal.Products),\n             linetype=\"dotted\", size=1, color = \"grey\")+\n    geom_text(aes(mean(Vegetal.Products), 8.1, label = \"veggie consumption\",\n                  hjust=0), size=2.8, vjust=1.40, angle=270,color = \"grey\")+\n    geom_text(aes(mean(Vegetal.Products), 8.1, label = \"average\", \n                  hjust=0), size=2.8, vjust=-0.85, angle=270, color = \"grey\")+\n    geom_hline(yintercept = mean(kcal_continents_trimmed$Animal.fats),\n               linetype=\"dotted\", size=1, color = \"grey\")+\n    geom_text(aes(27, mean(Animal.fats), label = \"meat consumption\",\n                  vjust=1.15), size=2.8, hjust=0, color =\"grey\")+\n    geom_text(aes(27, mean(Animal.fats), label = \"average\",\n                  vjust=-0.65), size=2.8, hjust=0, color = \"grey\")+\n  \n  theme_minimal()+\n  \n  #Titles\n  ggtitle(\"Eat your VEGGIES kids!\")+\n    theme(plot.title = element_text(size=18))+\n    theme(plot.title = element_text(face=\"italic\"))+\n  labs(y=\"Animal Fats\",\n       x=\"Vegetable Products\")+\n    theme(axis.title.x = element_text(margin = margin(t=6, b=5), size=13))+\n    theme(axis.title.y = element_text(margin = margin(r=5, l=5), size=13))+\n\n  #Quadrant labels\n  annotate(\"text\", x=43, y=-0.5, label = \"Veggie based diet\", size=4,\n           fontface = \"italic\", hjust=0)+\n  annotate(\"text\", x=27.5, y=7.4, label = \"Meat based diet\", size=4,\n           fontface = \"italic\", hjust=0)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nEurope\n\nCodeggplot(kcal_continents_trimmed, aes(x=Vegetal.Products, y=Animal.fats,\n        size=Deaths, text=paste(Country)))+\n  #scale_color_brewer(palette=\"Dark2\")+\n  geom_point(data = Europe, alpha=0.35, aes(size=(Deaths*1000)),\n             color = \"#7570B3\")+\n    scale_size_continuous(name = \"Deaths per 1000\")+\n    scale_x_continuous(limits = c(27, 48.5))+\n  \n  #US and high/low outliers\n  # geom_point(data = usa, aes(x=Vegetal.Products, y=Animal.fats), \n  #            color = \"#E7298A\", size=5)+\n  #   geom_label_repel(data = usa, aes(x=Vegetal.Products, y=Animal.fats, \n  #                   label = Country), fontface=\"bold\", size=4,\n  #                   nudge_x = -4.75, nudge_y = -1.0)+\n  # geom_point(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats),\n  #            color = \"#7570B3\", size=4)+\n  #   geom_label_repel(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats,\n  #                   label = Country), fontface=\"bold\", size=4,\n  #                   nudge_x = 2.75, nudge_y = -0.5)+\n  # geom_point(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats),\n  #            color = \"#1B9E77\")+\n  #   geom_label_repel(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats,\n  #                   label = Country), fontface=\"bold\", size=4, \n  #                   nudge_x = -1.5, nudge_y = 1.7)+\n  \n  #Quadrant lines\n  geom_vline(xintercept = mean(kcal_continents_trimmed$Vegetal.Products),\n             linetype=\"dotted\", size=1, color = \"grey\")+\n    geom_text(aes(mean(Vegetal.Products), 8.1, label = \"veggie consumption\",\n                  hjust=0), size=2.8, vjust=1.40, angle=270,color = \"grey\")+\n    geom_text(aes(mean(Vegetal.Products), 8.1, label = \"average\", \n                  hjust=0), size=2.8, vjust=-0.85, angle=270, color = \"grey\")+\n    geom_hline(yintercept = mean(kcal_continents_trimmed$Animal.fats),\n               linetype=\"dotted\", size=1, color = \"grey\")+\n    geom_text(aes(27, mean(Animal.fats), label = \"meat consumption\",\n                  vjust=1.15), size=2.8, hjust=0, color =\"grey\")+\n    geom_text(aes(27, mean(Animal.fats), label = \"average\",\n                  vjust=-0.65), size=2.8, hjust=0, color = \"grey\")+\n  \n  theme_minimal()+\n  \n  #Titles\n  ggtitle(\"Eat your VEGGIES kids!\")+\n    theme(plot.title = element_text(size=18))+\n    theme(plot.title = element_text(face=\"italic\"))+\n  labs(y=\"Animal Fats\",\n       x=\"Vegetable Products\")+\n    theme(axis.title.x = element_text(margin = margin(t=6, b=5), size=13))+\n    theme(axis.title.y = element_text(margin = margin(r=5, l=5), size=13))+\n\n  #Quadrant labels\n  annotate(\"text\", x=43, y=-0.5, label = \"Veggie based diet\", size=4,\n           fontface = \"italic\", hjust=0)+\n  annotate(\"text\", x=27.5, y=7.4, label = \"Meat based diet\", size=4,\n           fontface = \"italic\", hjust=0)\n\n\n\n\nAmericas\n\nCodeggplot(kcal_continents_trimmed, aes(x=Vegetal.Products, y=Animal.fats,\n        size=Deaths, text=paste(Country)))+\n  #scale_color_brewer(palette=\"Dark2\")+\n  geom_point(data = Americas, alpha=0.35, aes(size=(Deaths*1000)),\n             color = \"#E7298A\")+\n    scale_size_continuous(name = \"Deaths per 1000\")+\n    scale_x_continuous(limits = c(27, 48.5))+\n  \n  #US and high/low outliers\n  # geom_point(data = usa, aes(x=Vegetal.Products, y=Animal.fats), \n  #            color = \"#E7298A\", size=5)+\n  #   geom_label_repel(data = usa, aes(x=Vegetal.Products, y=Animal.fats, \n  #                   label = Country), fontface=\"bold\", size=4,\n  #                   nudge_x = -4.75, nudge_y = -1.0)+\n  # geom_point(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats),\n  #            color = \"#7570B3\", size=4)+\n  #   geom_label_repel(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats,\n  #                   label = Country), fontface=\"bold\", size=4,\n  #                   nudge_x = 2.75, nudge_y = -0.5)+\n  # geom_point(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats),\n  #            color = \"#1B9E77\")+\n  #   geom_label_repel(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats,\n  #                   label = Country), fontface=\"bold\", size=4, \n  #                   nudge_x = -1.5, nudge_y = 1.7)+\n  \n  #Quadrant lines\n  geom_vline(xintercept = mean(kcal_continents_trimmed$Vegetal.Products),\n             linetype=\"dotted\", size=1, color = \"grey\")+\n    geom_text(aes(mean(Vegetal.Products), 8.1, label = \"veggie consumption\",\n                  hjust=0), size=2.8, vjust=1.40, angle=270,color = \"grey\")+\n    geom_text(aes(mean(Vegetal.Products), 8.1, label = \"average\", \n                  hjust=0), size=2.8, vjust=-0.85, angle=270, color = \"grey\")+\n    geom_hline(yintercept = mean(kcal_continents_trimmed$Animal.fats),\n               linetype=\"dotted\", size=1, color = \"grey\")+\n    geom_text(aes(27, mean(Animal.fats), label = \"meat consumption\",\n                  vjust=1.15), size=2.8, hjust=0, color =\"grey\")+\n    geom_text(aes(27, mean(Animal.fats), label = \"average\",\n                  vjust=-0.65), size=2.8, hjust=0, color = \"grey\")+\n  \n  theme_minimal()+\n  \n  #Titles\n  ggtitle(\"Eat your VEGGIES kids!\")+\n    theme(plot.title = element_text(size=18))+\n    theme(plot.title = element_text(face=\"italic\"))+\n  labs(y=\"Animal Fats\",\n       x=\"Vegetable Products\")+\n    theme(axis.title.x = element_text(margin = margin(t=6, b=5), size=13))+\n    theme(axis.title.y = element_text(margin = margin(r=5, l=5), size=13))+\n\n  #Quadrant labels\n  annotate(\"text\", x=43, y=-0.5, label = \"Veggie based diet\", size=4,\n           fontface = \"italic\", hjust=0)+\n  annotate(\"text\", x=27.5, y=7.4, label = \"Meat based diet\", size=4,\n           fontface = \"italic\", hjust=0)\n\n\n\n\nAfrica\n\nCodeggplot(kcal_continents_trimmed, aes(x=Vegetal.Products, y=Animal.fats,\n        size=Deaths, text=paste(Country)))+\n  #scale_color_brewer(palette=\"Dark2\")+\n  geom_point(data = Africa, alpha=0.35, aes(size=(Deaths*1000)), \n             color = \"#1B9E77\")+\n    scale_size_continuous(name = \"Deaths per 1000\")+\n    scale_x_continuous(limits = c(27, 48.5))+\n  \n  #US and high/low outliers\n  # geom_point(data = usa, aes(x=Vegetal.Products, y=Animal.fats), \n  #            color = \"#E7298A\", size=5)+\n  #   geom_label_repel(data = usa, aes(x=Vegetal.Products, y=Animal.fats, \n  #                   label = Country), fontface=\"bold\", size=4,\n  #                   nudge_x = -4.75, nudge_y = -1.0)+\n  # geom_point(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats),\n  #            color = \"#7570B3\", size=4)+\n  #   geom_label_repel(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats,\n  #                   label = Country), fontface=\"bold\", size=4,\n  #                   nudge_x = 2.75, nudge_y = -0.5)+\n  # geom_point(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats),\n  #            color = \"#1B9E77\")+\n  #   geom_label_repel(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats,\n  #                   label = Country), fontface=\"bold\", size=4, \n  #                   nudge_x = -1.5, nudge_y = 1.7)+\n  \n  #Quadrant lines\n  geom_vline(xintercept = mean(kcal_continents_trimmed$Vegetal.Products),\n             linetype=\"dotted\", size=1, color = \"grey\")+\n    geom_text(aes(mean(Vegetal.Products), 8.1, label = \"veggie consumption\",\n                  hjust=0), size=2.8, vjust=1.40, angle=270,color = \"grey\")+\n    geom_text(aes(mean(Vegetal.Products), 8.1, label = \"average\", \n                  hjust=0), size=2.8, vjust=-0.85, angle=270, color = \"grey\")+\n    geom_hline(yintercept = mean(kcal_continents_trimmed$Animal.fats),\n               linetype=\"dotted\", size=1, color = \"grey\")+\n    geom_text(aes(27, mean(Animal.fats), label = \"meat consumption\",\n                  vjust=1.15), size=2.8, hjust=0, color =\"grey\")+\n    geom_text(aes(27, mean(Animal.fats), label = \"average\",\n                  vjust=-0.65), size=2.8, hjust=0, color = \"grey\")+\n  \n  theme_minimal()+\n  \n  #Titles\n  ggtitle(\"Eat your VEGGIES kids!\")+\n    theme(plot.title = element_text(size=18))+\n    theme(plot.title = element_text(face=\"italic\"))+\n  labs(y=\"Animal Fats\",\n       x=\"Vegetable Products\")+\n    theme(axis.title.x = element_text(margin = margin(t=6, b=5), size=13))+\n    theme(axis.title.y = element_text(margin = margin(r=5, l=5), size=13))+\n\n  #Quadrant labels\n  annotate(\"text\", x=43, y=-0.5, label = \"Veggie based diet\", size=4,\n           fontface = \"italic\", hjust=0)+\n  annotate(\"text\", x=27.5, y=7.4, label = \"Meat based diet\", size=4,\n           fontface = \"italic\", hjust=0)\n\n\n\n\nAll with US highlighted\n\nCodeggplot(kcal_continents_trimmed, aes(x=Vegetal.Products, y=Animal.fats,\n        size=Deaths, color=Continent, text=paste(Country)))+\n  scale_color_brewer(palette=\"Dark2\")+\n  geom_point(alpha=0.35, aes(size=(Deaths*1000)))+\n    scale_size_continuous(name = \"Deaths per 1000\")+\n    scale_x_continuous(limits = c(27, 48.5))+\n\n  #US and high/low outliers\n  geom_point(data = usa, aes(x=Vegetal.Products, y=Animal.fats),\n             color = \"#E7298A\", size=5)+\n    geom_label_repel(data = usa, aes(x=Vegetal.Products, y=Animal.fats,\n                    label = Country), fontface=\"bold\", size=4,\n                    nudge_x = -4.75, nudge_y = -1.0)+\n  # geom_point(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats),\n  #            color = \"#7570B3\", size=4)+\n  #   geom_label_repel(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats,\n  #                   label = Country), fontface=\"bold\", size=4,\n  #                   nudge_x = 2.75, nudge_y = -0.5)+\n  # geom_point(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats),\n  #            color = \"#1B9E77\")+\n  #   geom_label_repel(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats,\n  #                   label = Country), fontface=\"bold\", size=4, \n  #                   nudge_x = -1.5, nudge_y = 1.7)+\n  \n  #Quadrant lines\n  geom_vline(xintercept = mean(kcal_continents_trimmed$Vegetal.Products),\n             linetype=\"dotted\", size=1, color = \"grey\")+\n    geom_text(aes(mean(Vegetal.Products), 8.1, label = \"veggie consumption\",\n                  hjust=0), size=2.8, vjust=1.40, angle=270,color = \"grey\")+\n    geom_text(aes(mean(Vegetal.Products), 8.1, label = \"average\", \n                  hjust=0), size=2.8, vjust=-0.85, angle=270, color = \"grey\")+\n    geom_hline(yintercept = mean(kcal_continents_trimmed$Animal.fats),\n               linetype=\"dotted\", size=1, color = \"grey\")+\n    geom_text(aes(27, mean(Animal.fats), label = \"meat consumption\",\n                  vjust=1.15), size=2.8, hjust=0, color =\"grey\")+\n    geom_text(aes(27, mean(Animal.fats), label = \"average\",\n                  vjust=-0.65), size=2.8, hjust=0, color = \"grey\")+\n  \n  theme_minimal()+\n  \n  #Titles\n  ggtitle(\"Eat your VEGGIES kids!\")+\n    theme(plot.title = element_text(size=18))+\n    theme(plot.title = element_text(face=\"italic\"))+\n  labs(y=\"Animal Fats\",\n       x=\"Vegetable Products\")+\n    theme(axis.title.x = element_text(margin = margin(t=6, b=5), size=13))+\n    theme(axis.title.y = element_text(margin = margin(r=5, l=5), size=13))+\n\n  #Quadrant labels\n  annotate(\"text\", x=43, y=-0.5, label = \"Veggie based diet\", size=4,\n           fontface = \"italic\", hjust=0)+\n  annotate(\"text\", x=27.5, y=7.4, label = \"Meat based diet\", size=4,\n           fontface = \"italic\", hjust=0)\n\n\n\n\nAll with US and Slovakia highlighted\n\nCodeggplot(kcal_continents_trimmed, aes(x=Vegetal.Products, y=Animal.fats,\n        size=Deaths, color=Continent, text=paste(Country)))+\n  scale_color_brewer(palette=\"Dark2\")+\n  geom_point(alpha=0.35, aes(size=(Deaths*1000)))+\n    scale_size_continuous(name = \"Deaths per 1000\")+\n    scale_x_continuous(limits = c(27, 48.5))+\n\n  #US and high/low outliers\n  geom_point(data = usa, aes(x=Vegetal.Products, y=Animal.fats),\n             color = \"#E7298A\", size=5)+\n    geom_label_repel(data = usa, aes(x=Vegetal.Products, y=Animal.fats,\n                    label = Country), fontface=\"bold\", size=4,\n                    nudge_x = -4.75, nudge_y = -1.0)+\n  geom_point(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats),\n             color = \"#7570B3\", size=4)+\n    geom_label_repel(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats,\n                    label = Country), fontface=\"bold\", size=4,\n                    nudge_x = 2.75, nudge_y = -0.5)+\n  # geom_point(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats),\n  #            color = \"#1B9E77\")+\n  #   geom_label_repel(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats,\n  #                   label = Country), fontface=\"bold\", size=4, \n  #                   nudge_x = -1.5, nudge_y = 1.7)+\n  \n  #Quadrant lines\n  geom_vline(xintercept = mean(kcal_continents_trimmed$Vegetal.Products),\n             linetype=\"dotted\", size=1, color = \"grey\")+\n    geom_text(aes(mean(Vegetal.Products), 8.1, label = \"veggie consumption\",\n                  hjust=0), size=2.8, vjust=1.40, angle=270,color = \"grey\")+\n    geom_text(aes(mean(Vegetal.Products), 8.1, label = \"average\", \n                  hjust=0), size=2.8, vjust=-0.85, angle=270, color = \"grey\")+\n    geom_hline(yintercept = mean(kcal_continents_trimmed$Animal.fats),\n               linetype=\"dotted\", size=1, color = \"grey\")+\n    geom_text(aes(27, mean(Animal.fats), label = \"meat consumption\",\n                  vjust=1.15), size=2.8, hjust=0, color =\"grey\")+\n    geom_text(aes(27, mean(Animal.fats), label = \"average\",\n                  vjust=-0.65), size=2.8, hjust=0, color = \"grey\")+\n  \n  theme_minimal()+\n  \n  #Titles\n  ggtitle(\"Eat your VEGGIES kids!\")+\n    theme(plot.title = element_text(size=18))+\n    theme(plot.title = element_text(face=\"italic\"))+\n  labs(y=\"Animal Fats\",\n       x=\"Vegetable Products\")+\n    theme(axis.title.x = element_text(margin = margin(t=6, b=5), size=13))+\n    theme(axis.title.y = element_text(margin = margin(r=5, l=5), size=13))+\n\n  #Quadrant labels\n  annotate(\"text\", x=43, y=-0.5, label = \"Veggie based diet\", size=4,\n           fontface = \"italic\", hjust=0)+\n  annotate(\"text\", x=27.5, y=7.4, label = \"Meat based diet\", size=4,\n           fontface = \"italic\", hjust=0)\n\n\n\n\nAll with US, Slovakia, and Nigeria highlighted\n\nCodeggplot(kcal_continents_trimmed, aes(x=Vegetal.Products, y=Animal.fats,\n        size=Deaths, color=Continent, text=paste(Country)))+\n  scale_color_brewer(palette=\"Dark2\")+\n  geom_point(alpha=0.35, aes(size=(Deaths*1000)))+\n    scale_size_continuous(name = \"Deaths per 1000\")+\n    scale_x_continuous(limits = c(27, 48.5))+\n\n  #US and high/low outliers\n  geom_point(data = usa, aes(x=Vegetal.Products, y=Animal.fats),\n             color = \"#E7298A\", size=5)+\n    geom_label_repel(data = usa, aes(x=Vegetal.Products, y=Animal.fats,\n                    label = Country), fontface=\"bold\", size=4,\n                    nudge_x = -4.75, nudge_y = -1.0)+\n  geom_point(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats),\n             color = \"#7570B3\", size=4)+\n    geom_label_repel(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats,\n                    label = Country), fontface=\"bold\", size=4,\n                    nudge_x = 2.75, nudge_y = -0.5)+\n  geom_point(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats),\n             color = \"#1B9E77\")+\n    geom_label_repel(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats,\n                    label = Country), fontface=\"bold\", size=4,\n                    nudge_x = -1.5, nudge_y = 1.7)+\n  \n  #Quadrant lines\n  geom_vline(xintercept = mean(kcal_continents_trimmed$Vegetal.Products),\n             linetype=\"dotted\", size=1, color = \"grey\")+\n    geom_text(aes(mean(Vegetal.Products), 8.1, label = \"veggie consumption\",\n                  hjust=0), size=2.8, vjust=1.40, angle=270,color = \"grey\")+\n    geom_text(aes(mean(Vegetal.Products), 8.1, label = \"average\", \n                  hjust=0), size=2.8, vjust=-0.85, angle=270, color = \"grey\")+\n    geom_hline(yintercept = mean(kcal_continents_trimmed$Animal.fats),\n               linetype=\"dotted\", size=1, color = \"grey\")+\n    geom_text(aes(27, mean(Animal.fats), label = \"meat consumption\",\n                  vjust=1.15), size=2.8, hjust=0, color =\"grey\")+\n    geom_text(aes(27, mean(Animal.fats), label = \"average\",\n                  vjust=-0.65), size=2.8, hjust=0, color = \"grey\")+\n  \n  theme_minimal()+\n  \n  #Titles\n  ggtitle(\"Eat your VEGGIES kids!\")+\n    theme(plot.title = element_text(size=18))+\n    theme(plot.title = element_text(face=\"italic\"))+\n  labs(y=\"Animal Fats\",\n       x=\"Vegetable Products\")+\n    theme(axis.title.x = element_text(margin = margin(t=6, b=5), size=13))+\n    theme(axis.title.y = element_text(margin = margin(r=5, l=5), size=13))+\n\n  #Quadrant labels\n  annotate(\"text\", x=43, y=-0.5, label = \"Veggie based diet\", size=4,\n           fontface = \"italic\", hjust=0)+\n  annotate(\"text\", x=27.5, y=7.4, label = \"Meat based diet\", size=4,\n           fontface = \"italic\", hjust=0)\n\n\n\n\nEverything\n\nCodeggplot(kcal_continents_trimmed, aes(x=Vegetal.Products, y=Animal.fats,\n        size=Deaths, color=Continent, text=paste(Country)))+\n  scale_color_brewer(palette=\"Dark2\")+\n  geom_point(alpha=0.35, aes(size=(Deaths*1000)))+\n    scale_size_continuous(name = \"Deaths per 1000\")+\n    scale_x_continuous(limits = c(27, 48.5))+\n  \n  #US and high/low outliers\n  geom_point(data = usa, aes(x=Vegetal.Products, y=Animal.fats),\n             color = \"#E7298A\", size=5)+\n    geom_label_repel(data = usa, aes(x=Vegetal.Products, y=Animal.fats,\n                    label = Country), fontface=\"bold\", size=4,\n                    nudge_x = -4.75, nudge_y = -1.0)+\n  geom_point(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats),\n             color = \"#7570B3\", size=4)+\n    geom_label_repel(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats,\n                    label = Country), fontface=\"bold\", size=4,\n                    nudge_x = 2.75, nudge_y = -0.5)+\n  geom_point(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats),\n             color = \"#1B9E77\")+\n    geom_label_repel(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats,\n                    label = Country), fontface=\"bold\", size=4,\n                    nudge_x = -1.5, nudge_y = 1.7)+\n  \n  #Quadrant lines\n  geom_vline(xintercept = mean(kcal_continents_trimmed$Vegetal.Products),\n             linetype=\"dotted\", size=1, color = \"grey\")+\n    geom_text(aes(mean(Vegetal.Products), 8.1, label = \"veggie consumption\",\n                  hjust=0), size=2.8, vjust=1.40, angle=270,color = \"grey\")+\n    geom_text(aes(mean(Vegetal.Products), 8.1, label = \"average\", \n                  hjust=0), size=2.8, vjust=-0.85, angle=270, color = \"grey\")+\n    geom_hline(yintercept = mean(kcal_continents_trimmed$Animal.fats),\n               linetype=\"dotted\", size=1, color = \"grey\")+\n    geom_text(aes(27, mean(Animal.fats), label = \"meat consumption\",\n                  vjust=1.15), size=2.8, hjust=0, color =\"grey\")+\n    geom_text(aes(27, mean(Animal.fats), label = \"average\",\n                  vjust=-0.65), size=2.8, hjust=0, color = \"grey\")+\n  \n  theme_minimal()+\n  \n  #Titles\n  ggtitle(\"Eat your VEGGIES kids!\")+\n    theme(plot.title = element_text(size=18))+\n    theme(plot.title = element_text(face=\"italic\"))+\n  labs(y=\"Animal Fats\",\n       x=\"Vegetable Products\")+\n    theme(axis.title.x = element_text(margin = margin(t=6, b=5), size=13))+\n    theme(axis.title.y = element_text(margin = margin(r=5, l=5), size=13))+\n\n  #Quadrant labels\n  annotate(\"text\", x=43, y=-0.5, label = \"Veggie based diet\", size=4,\n           fontface = \"italic\", hjust=0)+\n  annotate(\"text\", x=27.5, y=7.4, label = \"Meat based diet\", size=4,\n           fontface = \"italic\", hjust=0)\n\n\n\n\nPlotly finale\n\nCodeveggie_plotly <- ggplot(kcal_continents_trimmed, aes(x=Vegetal.Products, y=Animal.fats,\n        size=Deaths, color=Continent, text=paste(Country)))+\n  scale_color_brewer(palette=\"Dark2\")+\n  geom_point(alpha=0.35, aes(size=(Deaths*1000)))+\n    scale_size_continuous(name = \"Deaths per 1000\")+\n    scale_x_continuous(limits = c(27, 48.5))+\n  \n  #US and high/low outliers\n  geom_point(data = usa, aes(x=Vegetal.Products, y=Animal.fats),\n             color = \"#E7298A\", size=5)+\n    geom_label_repel(data = usa, aes(x=Vegetal.Products, y=Animal.fats,\n                    label = Country), fontface=\"bold\", size=4,\n                    nudge_x = -4.75, nudge_y = -1.0)+\n  geom_point(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats),\n             color = \"#7570B3\", size=4)+\n    geom_label_repel(data = slovakia, aes(x=Vegetal.Products, y=Animal.fats,\n                    label = Country), fontface=\"bold\", size=4,\n                    nudge_x = 2.75, nudge_y = -0.5)+\n  geom_point(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats),\n             color = \"#1B9E77\")+\n    geom_label_repel(data = nigeria, aes(x=Vegetal.Products, y=Animal.fats,\n                    label = Country), fontface=\"bold\", size=4,\n                    nudge_x = -1.5, nudge_y = 1.7)+\n  \n  #Quadrant lines\n  geom_vline(xintercept = mean(kcal_continents_trimmed$Vegetal.Products),\n             linetype=\"dotted\", size=1, color = \"grey\")+\n    # geom_text(aes(mean(Vegetal.Products), 8.1, label = \"veggie consumption\",\n    #               hjust=0), size=2.8, vjust=1.40, angle=270,color = \"grey\")+\n    # geom_text(aes(mean(Vegetal.Products), 8.1, label = \"average\", \n    #               hjust=0), size=2.8, vjust=-0.85, angle=270, color = \"grey\")+\n    geom_hline(yintercept = mean(kcal_continents_trimmed$Animal.fats),\n               linetype=\"dotted\", size=1, color = \"grey\")+\n    # geom_text(aes(27, mean(Animal.fats), label = \"meat consumption\",\n    #               vjust=1.15), size=2.8, hjust=0, color =\"grey\")+\n    # geom_text(aes(27, mean(Animal.fats), label = \"average\",\n    #               vjust=-0.65), size=2.8, hjust=0, color = \"grey\")+\n  \n  theme_minimal()+\n  \n  #Titles\n  ggtitle(\"Eat your VEGGIES kids!\")+\n    theme(plot.title = element_text(size=18))+\n    theme(plot.title = element_text(face=\"italic\"))+\n  labs(y=\"Animal Fats\",\n       x=\"Vegetable Products\")+\n    theme(axis.title.x = element_text(margin = margin(t=6, b=5), size=13))+\n    theme(axis.title.y = element_text(margin = margin(r=5, l=5), size=13))\n\n  #Quadrant labels\n  # annotate(\"text\", x=43, y=-0.5, label = \"Veggie based diet\", size=4,\n  #          fontface = \"italic\", hjust=0)+\n  # annotate(\"text\", x=27.5, y=7.4, label = \"Meat based diet\", size=4,\n  #          fontface = \"italic\", hjust=0)\n\nggplotly(veggie_plotly, tooltip = \"text\")\n\nWarning in geom2trace.default(dots[[1L]][[1L]], dots[[2L]][[1L]], dots[[3L]][[1L]]): geom_GeomLabelRepel() has yet to be implemented in plotly.\n  If you'd like to see this geom implemented,\n  Please open an issue with your example code at\n  https://github.com/ropensci/plotly/issues\n\nWarning in geom2trace.default(dots[[1L]][[1L]], dots[[2L]][[1L]], dots[[3L]][[1L]]): geom_GeomLabelRepel() has yet to be implemented in plotly.\n  If you'd like to see this geom implemented,\n  Please open an issue with your example code at\n  https://github.com/ropensci/plotly/issues\n\nWarning in geom2trace.default(dots[[1L]][[1L]], dots[[2L]][[1L]], dots[[3L]][[1L]]): geom_GeomLabelRepel() has yet to be implemented in plotly.\n  If you'd like to see this geom implemented,\n  Please open an issue with your example code at\n  https://github.com/ropensci/plotly/issues"
  },
  {
    "objectID": "posts/DATA503_FinalProject/index.html",
    "href": "posts/DATA503_FinalProject/index.html",
    "title": "Data Engineering Fundementals (DATA-503)",
    "section": "",
    "text": "Clicking on the image below will take you to a project that involved reviewing a given data set and addressing some questions of interest. The process involved the use of R for data wrangling, analysis and visualizations. This work has not been polished for publication and remains in its original form.\n\n\n\nFoundations of Data Science Final Report"
  },
  {
    "objectID": "posts/Interactive_ggiraph_2-20-23/index.html",
    "href": "posts/Interactive_ggiraph_2-20-23/index.html",
    "title": "Interactive plot with ggiraph",
    "section": "",
    "text": "Codeknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.0 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nCodelibrary(ggiraph)\nlibrary(ggthemes)\nlibrary(viridis)\n\nLoading required package: viridisLite\n\nCodelibrary(lubridate)\n\nLoading required package: timechange\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nCodelibrary(patchwork)"
  },
  {
    "objectID": "posts/Interactive_ggiraph_2-20-23/index.html#data-setup",
    "href": "posts/Interactive_ggiraph_2-20-23/index.html#data-setup",
    "title": "Interactive plot with ggiraph",
    "section": "Data setup",
    "text": "Data setup\n\nCode# Read in data\ndata(\"mtcars\")\n\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2"
  },
  {
    "objectID": "posts/Interactive_ggiraph_2-20-23/index.html#link-the-two-charts-together",
    "href": "posts/Interactive_ggiraph_2-20-23/index.html#link-the-two-charts-together",
    "title": "Interactive plot with ggiraph",
    "section": "Link the two charts together",
    "text": "Link the two charts together\n\nCodegirafe(code = print(cars1 + cars2), \n       width_svg = 8, height_svg = 4) %>% \n  girafe_options(opts_hover(css = \"fill:cyan;\"))"
  },
  {
    "objectID": "posts/Interactive_ggiraph_2-20-23/index.html#adding-titles-labels-and-adjustments",
    "href": "posts/Interactive_ggiraph_2-20-23/index.html#adding-titles-labels-and-adjustments",
    "title": "Interactive plot with ggiraph",
    "section": "Adding titles, labels and adjustments",
    "text": "Adding titles, labels and adjustments\n\nCodecars1 <- cars1 +\n  labs(title = \"1974 Motor Trend Road Tests\",\n       subtitle = \"Horsepower, Miles per gallon, Number of cylinders\",\n       x = \"\",\n       y = \"Horsepower\")\n\n\ncars2 <- cars2 +\n  labs(title = \"1974 Motor Trend Road Tests\",\n       subtitle = \"Quarter-mile time, Vehicle weight, Engine displacement\",\n       x = \"\",\n       y = \"Quarter Mile Time (Seconds)\")"
  },
  {
    "objectID": "posts/Interactive_ggiraph_2-20-23/index.html#linking-the-two-final-charts-together",
    "href": "posts/Interactive_ggiraph_2-20-23/index.html#linking-the-two-final-charts-together",
    "title": "Interactive plot with ggiraph",
    "section": "Linking the two final charts together",
    "text": "Linking the two final charts together\n\nCodegirafe(code = print(cars1 + cars2), \n       width_svg = 12, height_svg = 7) %>% \n  girafe_options(opts_hover(css = \"fill:cyan;\"))"
  },
  {
    "objectID": "posts/Interactive_Plotly_2-20-23/index.html",
    "href": "posts/Interactive_Plotly_2-20-23/index.html",
    "title": "Interactive plot with Plotly",
    "section": "",
    "text": "Codeknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.0 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nCodelibrary(ggiraph)\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nCodelibrary(ggthemes)\nlibrary(viridis)\n\nLoading required package: viridisLite\n\nCodelibrary(lubridate)\n\nLoading required package: timechange\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union"
  },
  {
    "objectID": "posts/Interactive_Plotly_2-20-23/index.html#data-setup",
    "href": "posts/Interactive_Plotly_2-20-23/index.html#data-setup",
    "title": "Interactive plot with Plotly",
    "section": "Data setup",
    "text": "Data setup\n\nCode# Read in data\nutilities <- read.csv(\"..\\\\..\\\\data\\\\utilities.csv\") %>% \n        rename(\"Desc\" = \"Description.of.transaction\")\n\n#convert Date to date format\nutilities$Date <- mdy(utilities$Date)\n\n# Breaking out month and year\nutilities <- utilities %>% \n  mutate(yr_month = as.Date(cut(Date, breaks = \"month\"))) %>% \n  mutate(year = as.Date(cut(Date, breaks = \"year\"))) %>% \n  filter(Date < \"2023/01/01\")\n\n# Removing unneeded columns\nutilities <- utilities %>% \n  filter(Desc != \"Car Insurance\" & Desc != \"Trash\")"
  },
  {
    "objectID": "posts/Interactive_Plotly_2-20-23/index.html#creating-averages-per-month-and-year",
    "href": "posts/Interactive_Plotly_2-20-23/index.html#creating-averages-per-month-and-year",
    "title": "Interactive plot with Plotly",
    "section": "Creating averages per month and year",
    "text": "Creating averages per month and year\n\nCodeutilities <- utilities %>% \n  group_by(Desc, year) %>% \n  mutate(avg_yearly = mean(Out))\n\nutilities <- utilities %>% \n  group_by(Desc, yr_month) %>% \n  mutate(avg_monthly = mean(Out))"
  },
  {
    "objectID": "posts/Interactive_Plotly_2-20-23/index.html#initial-plot",
    "href": "posts/Interactive_Plotly_2-20-23/index.html#initial-plot",
    "title": "Interactive plot with Plotly",
    "section": "Initial plot",
    "text": "Initial plot\n\nCodemonthly <- utilities %>% \n  ggplot(aes(yr_month, Out, color=Desc))+\n    geom_line(size = .75)+\n      facet_wrap(~Desc)\n\nmonthly"
  },
  {
    "objectID": "posts/Interactive_Plotly_2-20-23/index.html#cleaning-up-plot",
    "href": "posts/Interactive_Plotly_2-20-23/index.html#cleaning-up-plot",
    "title": "Interactive plot with Plotly",
    "section": "Cleaning up plot",
    "text": "Cleaning up plot\n\nCodemonthly2 <- monthly + \n  theme_solarized() +\n  labs(title = \"Monthly Utility Costs 2018 through 2022\",\n       subtitle = \"1680sf home with family of four between 2018 and 2020\\n2480sf home with family of five between 2020 and 2022\",\n       x = \"Date\",\n       y = \"Monthly Expense\",\n       color = \"Utility Type\")+\n  theme(plot.title = element_text(hjust = 0.5, size = 14, face = 'bold', color = 'black'),\n        plot.subtitle = element_text(size = 10, face = 'italic'),\n        axis.title.x = element_text(color = 'black'),\n        axis.title.y = element_text(color = 'black'),\n        legend.position = \"none\")+\n  scale_y_continuous(sec.axis = sec_axis(~.))+\n  scale_color_viridis(discrete = TRUE)\n  \nmonthly2"
  },
  {
    "objectID": "posts/Interactive_Plotly_2-20-23/index.html#converting-to-plotly",
    "href": "posts/Interactive_Plotly_2-20-23/index.html#converting-to-plotly",
    "title": "Interactive plot with Plotly",
    "section": "Converting to plotly",
    "text": "Converting to plotly\n\nCodeggmonthly <- ggplotly(monthly2) %>%\n  layout(title = list(y = .95, xref = \"plot\"),\n         margin = list(l = 75, t = 75, b = 75, r = 50))\n\nggmonthly"
  },
  {
    "objectID": "posts/presentation_2-27-23/index.html",
    "href": "posts/presentation_2-27-23/index.html",
    "title": "Portfolio Presentation",
    "section": "",
    "text": "Created with Quarto markdown and reveal.js"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#data-engineering-1",
    "href": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#data-engineering-1",
    "title": "Data Science Portfolio",
    "section": "Data Engineering",
    "text": "Data Engineering\n\nUsing APIs to scrape data and create SQL databases\n\nget_nps_func <- function(){\n  #Initial code for retrieving data from site\n  nps_get <- read_html('https://developer.nps.gov/api/v1/alerts?api_key=...obfuscated...')\n  \n  #Pulling the JSON data from the html(?)\n  nps_json <- nps_get %>% html_text %>% fromJSON\n  \n  #Pulling the data frame from the JSON data(?)\n  nps_data <- nps_json$data\n  \n  return(nps_data)\n}\n\n#Establish connection to local\ncon_local <- dbConnect(RPostgres::Postgres(),\n                       dbname = 'railway',\n                       host = Sys.getenv('PGHOST'),\n                       port = Sys.getenv('PGPORT'),\n                       user = Sys.getenv('PGUSER'),\n                       password = Sys.getenv('PGPASSWORD'))\n\n#Create table within local database\ndbExecute(con_local, \"CREATE TABLE IF NOT EXISTS nps_alerts(\n                      id TEXT, url TEXT,\n                      title TEXT, parkCode TEXT,\n                      description TEXT, category TEXT,\n                      lastIndexedDate TEXT, time TIMESTAMPTZ,\n                      PRIMARY KEY (id))\")\n\n#looping and sleeping\nwhile (TRUE) {\n  #Run function to gather data\n  nps_input <- get_nps_func()\n  \n  #Insert from R table created from scrape into local database\n  dbExecute (con_local, \"INSERT INTO nps_alerts\n            (id,\n             url,\n             title,\n             parkCode,\n             description,\n             category,\n             lastIndexedDate,\n             time)\n             VALUES ($1, $2, $3, $4, $5, $6, $7, current_timestamp)\n             ON CONFLICT (id) DO NOTHING\",\n             params = unname(nps_input))\n  print(\"Transaction ended, waiting for next response.\")\n  Sys.sleep(3600)\n}"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#data-engineering-2",
    "href": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#data-engineering-2",
    "title": "Data Science Portfolio",
    "section": "Data Engineering",
    "text": "Data Engineering\n\nCreating, structuring, and maintaining SQL databases"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#data-exploration-and-visualization-1",
    "href": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#data-exploration-and-visualization-1",
    "title": "Data Science Portfolio",
    "section": "Data Exploration and Visualization",
    "text": "Data Exploration and Visualization"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#data-exploration-and-visualization-2",
    "href": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#data-exploration-and-visualization-2",
    "title": "Data Science Portfolio",
    "section": "Data Exploration and Visualization",
    "text": "Data Exploration and Visualization"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#data-exploration-and-visualization-3",
    "href": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#data-exploration-and-visualization-3",
    "title": "Data Science Portfolio",
    "section": "Data Exploration and Visualization",
    "text": "Data Exploration and Visualization"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#interactive-visualizations-with-plotly",
    "href": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#interactive-visualizations-with-plotly",
    "title": "Data Science Portfolio",
    "section": "Interactive Visualizations with Plotly",
    "text": "Interactive Visualizations with Plotly"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#interactive-visualizations-with-plotly-1",
    "href": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#interactive-visualizations-with-plotly-1",
    "title": "Data Science Portfolio",
    "section": "Interactive Visualizations with Plotly",
    "text": "Interactive Visualizations with Plotly"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#interactive-visualizations-with-ggiraph",
    "href": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#interactive-visualizations-with-ggiraph",
    "title": "Data Science Portfolio",
    "section": "Interactive Visualizations with ggiraph",
    "text": "Interactive Visualizations with ggiraph"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#tables-1",
    "href": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#tables-1",
    "title": "Data Science Portfolio",
    "section": "Tables",
    "text": "Tables"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#tables-2",
    "href": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#tables-2",
    "title": "Data Science Portfolio",
    "section": "Tables",
    "text": "Tables"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#contact-me",
    "href": "presentations/Feb-27-23_self_presentation/Feb-27-23_self_presentation.html#contact-me",
    "title": "Data Science Portfolio",
    "section": "Contact me:",
    "text": "Contact me:\n\nLinkedIn: https://www.linkedin.com/in/jessedebolt\nGithub: https://github.com/jessedebolt/Portfolio_project\nWebsite: https://jessedebolt-portfolio.netlify.app/\nEmail: jessedebolt@comcast.net"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/HW5_utilities_plotly.html",
    "href": "presentations/Feb-27-23_self_presentation/HW5_utilities_plotly.html",
    "title": "Utilities - Plotly",
    "section": "",
    "text": "Codeknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.0 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nCodelibrary(ggiraph)\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nCodelibrary(ggthemes)\nlibrary(viridis)\n\nLoading required package: viridisLite\n\nCodelibrary(lubridate)\n\nLoading required package: timechange\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/HW5_utilities_plotly.html#data-setup",
    "href": "presentations/Feb-27-23_self_presentation/HW5_utilities_plotly.html#data-setup",
    "title": "Utilities - Plotly",
    "section": "Data setup",
    "text": "Data setup\n\nCode# Read in data\nutilities <- read.csv(\"..\\\\..\\\\data\\\\utilities.csv\") %>% \n        rename(\"Desc\" = \"Description.of.transaction\")\n\n#convert Date to date format\nutilities$Date <- mdy(utilities$Date)\n\n# Breaking out month and year\nutilities <- utilities %>% \n  mutate(yr_month = as.Date(cut(Date, breaks = \"month\"))) %>% \n  mutate(year = as.Date(cut(Date, breaks = \"year\"))) %>% \n  filter(Date < \"2023/01/01\")\n\n# Removing unneeded columns\nutilities <- utilities %>% \n  filter(Desc != \"Car Insurance\" & Desc != \"Trash\")"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/HW5_utilities_plotly.html#creating-averages-per-month-and-year",
    "href": "presentations/Feb-27-23_self_presentation/HW5_utilities_plotly.html#creating-averages-per-month-and-year",
    "title": "Utilities - Plotly",
    "section": "Creating averages per month and year",
    "text": "Creating averages per month and year\n\nCodeutilities <- utilities %>% \n  group_by(Desc, year) %>% \n  mutate(avg_yearly = mean(Out))\n\nutilities <- utilities %>% \n  group_by(Desc, yr_month) %>% \n  mutate(avg_monthly = mean(Out))"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/HW5_utilities_plotly.html#initial-plot",
    "href": "presentations/Feb-27-23_self_presentation/HW5_utilities_plotly.html#initial-plot",
    "title": "Utilities - Plotly",
    "section": "Initial plot",
    "text": "Initial plot\n\nCodemonthly <- utilities %>% \n  ggplot(aes(yr_month, Out, color=Desc))+\n    geom_line(size = .75)+\n      facet_wrap(~Desc)\n\nmonthly"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/HW5_utilities_plotly.html#cleaning-up-plot",
    "href": "presentations/Feb-27-23_self_presentation/HW5_utilities_plotly.html#cleaning-up-plot",
    "title": "Utilities - Plotly",
    "section": "Cleaning up plot",
    "text": "Cleaning up plot\n\nCodemonthly2 <- monthly + \n  theme_solarized() +\n  labs(title = \"Monthly Utility Costs 2018 through 2022\",\n       subtitle = \"1680sf home with family of four between 2018 and 2020\\n2480sf home with family of five between 2020 and 2022\",\n       x = \"Date\",\n       y = \"Monthly Expense\",\n       color = \"Utility Type\")+\n  theme(plot.title = element_text(hjust = 0.5, size = 14, face = 'bold', color = 'black'),\n        plot.subtitle = element_text(size = 10, face = 'italic'),\n        axis.title.x = element_text(color = 'black'),\n        axis.title.y = element_text(color = 'black'),\n        legend.position = \"none\")+\n  scale_y_continuous(sec.axis = sec_axis(~.))+\n  scale_color_viridis(discrete = TRUE)\n  \nmonthly2"
  },
  {
    "objectID": "presentations/Feb-27-23_self_presentation/HW5_utilities_plotly.html#converting-to-plotly",
    "href": "presentations/Feb-27-23_self_presentation/HW5_utilities_plotly.html#converting-to-plotly",
    "title": "Utilities - Plotly",
    "section": "Converting to plotly",
    "text": "Converting to plotly\n\nCodeggmonthly <- ggplotly(monthly2) %>%\n  layout(title = list(y = .95, xref = \"plot\"),\n         margin = list(l = 75, t = 75, b = 75, r = 50))\n\nggmonthly"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects Blog",
    "section": "",
    "text": "Portfolio Presentation\n\n\n\n\n\n\n\nVisualizations\n\n\nInteractive\n\n\n\n\n\n\n\n\n\n\n\nApr 17, 2023\n\n\nJesse DeBolt\n\n\n\n\n\n\n  \n\n\n\n\nPortfolio Presentation\n\n\n\n\n\n\n\nVisualizations\n\n\nInteractive\n\n\n\n\n\n\n\n\n\n\n\nFeb 27, 2023\n\n\nJesse DeBolt\n\n\n\n\n\n\n  \n\n\n\n\nInteractive plot with ggiraph\n\n\n\n\n\n\n\nVisualizations\n\n\nInteractive\n\n\n\n\n\n\n\n\n\n\n\nFeb 20, 2023\n\n\nJesse DeBolt\n\n\n\n\n\n\n  \n\n\n\n\nInteractive plot with Plotly\n\n\n\n\n\n\n\nVisualizations\n\n\nInteractive\n\n\n\n\n\n\n\n\n\n\n\nFeb 20, 2023\n\n\nJesse DeBolt\n\n\n\n\n\n\n  \n\n\n\n\nTidy Tuesday Recreation\n\n\n\n\n\n\n\nVisualizations\n\n\nTidy Tuesday\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2023\n\n\nJesse DeBolt\n\n\n\n\n\n\n  \n\n\n\n\nTable Examples\n\n\n\n\n\n\n\nVisualizations\n\n\nTables\n\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2023\n\n\nJesse DeBolt\n\n\n\n\n\n\n  \n\n\n\n\nData Science Fundementals (DATA-501)\n\n\n\n\n\n\n\nEngineering\n\n\nAnalysis\n\n\nVisualizations\n\n\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\nJesse DeBolt\n\n\n\n\n\n\n  \n\n\n\n\nData Visualization (DATA-502)\n\n\n\n\n\n\n\nExploritory\n\n\nVisualizations\n\n\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\nJesse DeBolt & Issac Johnson\n\n\n\n\n\n\n  \n\n\n\n\nData Engineering Fundementals (DATA-503)\n\n\n\n\n\n\n\nEngineering\n\n\nDocker\n\n\nAPI\n\n\nVisualizations\n\n\n\n\n\n\n\n\n\n\n\nDec 9, 2022\n\n\nJesse DeBolt\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Resume.html",
    "href": "Resume.html",
    "title": "Resume",
    "section": "",
    "text": "Professional Experience:\n\n➢ Supervisor: Manufacturing Engineering and Cost Estimation\n\nSulzer Pumps (US), Inc. (Portland, Oregon)\nOctober, 2020 to July 1, 2022\n\nManaged a department of up to 15 coworkers in four different disciplines across three separate entities.\nChampioned multiple continuous improvement projects working with multiple department representative across several areas including manufacturing, purchasing, engineering, quality, and sales.\nLed the development of a new cost system configurator and costing database tool that enabled the simple selection of product and options, producing final cost estimates with accurate results.\n\n\n➢ Senior Manufacturing Engineer/Cost System Analyst\n\nSulzer Pumps (US), Inc. (Portland, Oregon)\nMarch, 2006 to October, 2020\n\nCreated and maintained standard operating procedures in compliance with ISO 9001.\nSupported Sales by creating accurate cost estimations for all engineered products based on customer specifications and engineering reviews.\nManaged large scale project to support in-house cost estimating software.\nAssisted in the development and maintenance of several databases of standard material costs and manufacturing labor hours to ensure accurate information for estimating future projects resulting in a 95% reduction in shop floor routing generation lead-time.\n\n\n➢ Process Engineer II – Lean Manufacturing\n\nJAE Oregon, Inc. (Tualatin, Oregon)\nOctober, 2003 to March, 2006\n\nTrained and managed various improvement teams including Value Stream Mapping, 5S, One Piece Flow, Standardized Work, and Setup Reduction.\nManaged improvement suggestion (Kaizen Teian) program and made improvements resulting in a 130% increase in employee participation.\nReduced inventory of consumable materials 75% and test materials 30% by establishing a Kanban system for each.\n\n\n➢ Manufacturing Engineer/Lean Facilitator\n\nSauer-Danfoss Company, formerly Compact Controls (Hillsboro, Oregon)\n\nFebruary, 1999 to October, 2003\n\nDeveloped, with a team of worldwide trainers, various lean manufacturing courses.\nCreated and maintained various documents in accordance with ISO 9001.\\\nReviewed engineering change documents, conducted process FMEAs, maintained routings in MRP system, and facilitated implementation of new and transferred products into assembly.\n\n\n\n\n\n\nGoals:\nSenior level manufacturing engineer with experience improving quality, profitability, and process flows within both high yield manufacturing and engineered capital goods markets. Working to expand knowledge and experience in the field of data sciences, specifically data engineering.\n\n\nEducation:\n\nMaster of Science in Data Science (expected graduation: August 2023), Willamette University\nBachelor of Science in Manufacturing Engineering Technology,\nOregon Institute of Technology, Klamath Falls, OR\nVarious Harvard ManagerMentor corporate manager skills modules\nVarious self-paced online lessons focused on Statistics, Data Science, Python, R, SQL, and Lean Six Sigma\n\n\n\nSkills and abilities:\n\nSelf-directed and able to manage multiple projects with changing priorities and deadlines.\nMotivated, highly organized, and goal oriented.\nStrong skills in interpersonal communications, composition, and technical writing.\nLeading and participating on cost reduction projects that collaborate with various process owners.\nComputer expertise / skill level:\n\nMicrosoft Office Products (including Project and Visio) / proficient\nVisual Studio Code (VS Code) / advanced beginner\nMicrosoft SQL Server Management Studio (SSMS) / competent\nPython, C, R, and SQL / beginner\nSAP ERP system / expert"
  },
  {
    "objectID": "Testing_folder/Resume.html",
    "href": "Testing_folder/Resume.html",
    "title": "Resume",
    "section": "",
    "text": "Professional Experience:\n\n➢ Supervisor: Manufacturing Engineering and Cost Estimation\n\nSulzer Pumps (US), Inc. (Portland, Oregon)\nOctober, 2020 to July 1, 2022\n\nManaged a department of up to 15 coworkers in four different disciplines across three separate entities.\nChampioned multiple continuous improvement projects working with multiple department representative across several areas including manufacturing, purchasing, engineering, quality, and sales.\nLed the development of a new cost system configurator and costing database tool that enabled the simple selection of product and options, producing final cost estimates with accurate results.\n\n➢ Senior Manufacturing Engineer/Cost System Analyst\n\nSulzer Pumps (US), Inc. (Portland, Oregon)\nMarch, 2006 to October, 2020\n\nCreated and maintained standard operating procedures in compliance with ISO 9001.\nSupported Sales by creating accurate cost estimations for all engineered products based on customer specifications and engineering reviews.\nManaged large scale project to support in-house cost estimating software.\nAssisted in the development and maintenance of several databases of standard material costs and manufacturing labor hours to ensure accurate information for estimating future projects resulting in a 95% reduction in shop floor routing generation lead-time.\n\n\n➢ Process Engineer II – Lean Manufacturing\n\nJAE Oregon, Inc. (Tualatin, Oregon)\nOctober, 2003 to March, 2006\n\nTrained and managed various improvement teams including Value Stream Mapping, 5S, One Piece Flow, Standardized Work, and Setup Reduction.\nManaged improvement suggestion (Kaizen Teian) program and made improvements resulting in a 130% increase in employee participation.\nReduced inventory of consumable materials 75% and test materials 30% by establishing a Kanban system for each.\n\n\n➢ Manufacturing Engineer/Lean Facilitator\n\nSauer-Danfoss Company, formerly Compact Controls (Hillsboro, Oregon)\n\nFebruary, 1999 to October, 2003\n\nDeveloped, with a team of worldwide trainers, various lean manufacturing courses.\nCreated and maintained various documents in accordance with ISO 9001.\\\nReviewed engineering change documents, conducted process FMEAs, maintained routings in MRP system, and facilitated implementation of new and transferred products into assembly.\n\n\n\n\n\n\nGoals:\nSenior level manufacturing engineer with experience improving quality, profitability, and process flows within both high yield manufacturing and engineered capital goods markets. Working to expand knowledge and experience in the field of data sciences, specifically data engineering.\n\n\nEducation:\n\nMaster of Science in Data Science (expected graduation: August 2023), Willamette University\nBachelor of Science in Manufacturing Engineering Technology,\nOregon Institute of Technology, Klamath Falls, OR\nVarious Harvard ManagerMentor corporate manager skills modules\nVarious self-paced online lessons focused on Statistics, Data Science, Python, R, SQL, and Lean Six Sigma\n\n\n\nSkills and abilities:\n\nSelf-directed and able to manage multiple projects with changing priorities and deadlines.\nMotivated, highly organized, and goal oriented.\nStrong skills in interpersonal communications, composition, and technical writing.\nLeading and participating on cost reduction projects that collaborate with various process owners.\nComputer expertise / skill level:\n\nMicrosoft Office Products (including Project and Visio) / proficient\nVisual Studio Code (VS Code) / advanced beginner\nMicrosoft SQL Server Management Studio (SSMS) / competent\nPython, C, R, and SQL / beginner\nSAP ERP system / expert"
  },
  {
    "objectID": "posts/Shiny_4-17-23/index.html",
    "href": "posts/Shiny_4-17-23/index.html",
    "title": "Portfolio Presentation",
    "section": "",
    "text": "Created with Quarto markdown and reveal.js"
  }
]